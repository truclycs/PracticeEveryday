{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(xml_path):\n",
    "    tree = ET.parse(str(xml_path))\n",
    "    image_info = {'image_name': tree.find('filename').text,\n",
    "                  'height': int(tree.find('size').find('height').text),\n",
    "                  'width': int(tree.find('size').find('width').text),\n",
    "                  'depth': int(tree.find('size').find('depth').text)}\n",
    "    label_info = []\n",
    "    objects = tree.findall('object')\n",
    "    for obj in objects:\n",
    "        bndbox = obj.find('bndbox')\n",
    "        bbox = np.int32([bndbox.find('xmin').text,\n",
    "                        bndbox.find('ymin').text,\n",
    "                        bndbox.find('xmax').text,\n",
    "                        bndbox.find('ymax').text])\n",
    "        label = obj.find('name').text\n",
    "        label_info.append({'label': label, 'bbox': bbox})\n",
    "    return image_info, label_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "mask_dir = Path('./VOC2007/Annotations/')\n",
    "image_dir = Path('./VOC2007/JPEGImages/')\n",
    "xml_paths = list(mask_dir.glob('*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import xml.etree.ElementTree as ET\n",
    "from torch.utils.data import Dataset\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, image_pattern, label_pattern, classes, transforms=None):\n",
    "        super(VOCDataset, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.transforms = transforms if transforms else []\n",
    "        image_paths = natsorted(list(Path(image_dir).glob(f'{image_pattern}')), key=lambda x: str(x.stem))\n",
    "        label_paths = natsorted(list(Path(label_dir).glob(f'{label_pattern}')), key=lambda x: str(x.stem))\n",
    "        self.data_pairs = [[image, label] for image, label in zip(image_paths, label_paths)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)\n",
    "    \n",
    "    def _get_label_info(self, label_path):\n",
    "        tree = ET.parse(str(label_path))\n",
    "        image_info = {'image_name': tree.find('filename').text,\n",
    "                      'height': int(tree.find('size').find('height').text),\n",
    "                      'width': int(tree.find('size').find('width').text),\n",
    "                      'depth': int(tree.find('size').find('depth').text)}\n",
    "        label_info = []\n",
    "        objects = tree.findall('object')\n",
    "        for obj in objects:\n",
    "            bndbox = obj.find('bndbox')\n",
    "            bbox = np.int32([bndbox.find('xmin').text,\n",
    "                             bndbox.find('ymin').text,\n",
    "                             bndbox.find('xmax').text,\n",
    "                             bndbox.find('ymax').text])\n",
    "            label_name = obj.find('name').text\n",
    "            label_info.append({'label': label_name, 'bbox': bbox})\n",
    "\n",
    "        return image_info, label_info\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label_path = self.data_pairs[idx]\n",
    "        sample_info, label_info = self._get_label_info(label_path)\n",
    "        sample = cv2.imread(str(image_path))\n",
    "        boxes = [label['bbox'] for label in label_info]\n",
    "        labels = [self.classes[label['label']] for label in label_info]\n",
    "\n",
    "        bbs = BoundingBoxesOnImage([BoundingBox(x1=box[0], y1=box[1], x2=box[2], y2=box[3], label=label)\n",
    "                                    for box, label in zip(boxes, labels)], shape=sample.shape)\n",
    "        for transform in random.sample(self.transforms, k=random.randint(0, len(self.transforms))):\n",
    "            sample, bbs = transform(image=sample, bounding_boxes=bbs)\n",
    "\n",
    "        boxes = [[bb.x1, bb.y1, bb.x2, bb.y2] for bb in bbs.bounding_boxes]\n",
    "        labels = [bb.label for bb in bbs.bounding_boxes]\n",
    "\n",
    "        # Convert to Torch Tensor\n",
    "        labels = torch.from_numpy(np.asarray(labels)).to(torch.int64)\n",
    "        boxes = torch.from_numpy(np.asarray(boxes)).to(torch.float32)\n",
    "        areas = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        # Target\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = image_id\n",
    "        target['area'] = areas\n",
    "\n",
    "        # Image\n",
    "        sample = np.ascontiguousarray(sample)\n",
    "        sample = torch.from_numpy(sample)\n",
    "        sample = sample.permute(2, 0, 1).to(torch.float)\n",
    "        sample = (sample - sample.mean()) / sample.std()\n",
    "\n",
    "        return sample, target, sample_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "\n",
    "label_dir = './VOC2007/Annotations/'\n",
    "image_dir = './VOC2007/JPEGImages/'\n",
    "image_pattern = '*.jpg'\n",
    "label_pattern = '*.xml'\n",
    "classes2idx = {'chair': 1,\n",
    "           'car': 2,\n",
    "           'horse': 3,\n",
    "           'person': 4,\n",
    "           'bicycle': 5,\n",
    "           'cat': 6,\n",
    "           'dog': 7,\n",
    "           'train': 8,\n",
    "           'aeroplane': 9,\n",
    "           'diningtable': 10,\n",
    "           'tvmonitor': 11,\n",
    "           'bird': 12,\n",
    "           'bottle': 13,\n",
    "           'sheep': 14,\n",
    "           'cow': 15,\n",
    "           'boat': 16, \n",
    "           'sofa': 17,\n",
    "           'pottedplant': 18,\n",
    "           'motorbike': 19,\n",
    "           'bus': 20}\n",
    "transforms = [iaa.Rotate(90)]\n",
    "voc_set = VOCDataset(image_dir=image_dir,\n",
    "                     label_dir=label_dir,\n",
    "                     image_pattern=image_pattern,\n",
    "                     label_pattern=label_pattern,\n",
    "                     classes=classes2idx,\n",
    "                     transforms=transforms)\n",
    "from torch.utils.data import DataLoader\n",
    "voc_loader = DataLoader(voc_set, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in voc_loader:\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "voc_iter = iter(voc_loader)\n",
    "samples, targets, sample_infos = next(voc_iter)\n",
    "for sample, target in zip(samples, targets):\n",
    "    image = (((sample - sample.min()) / (sample.max() - sample.min())) * 255.).permute(1, 2, 0).to(torch.uint8).numpy()\n",
    "    boxes = target['boxes']\n",
    "    labels = target['labels']\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color=(0, 255, 0), thickness=1)\n",
    "    cv2.imshow('image', image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample, target, sample_info = voc_set[10]\n",
    "print(target)\n",
    "image = (sample - sample.min()) / (sample.max() - sample.min())\n",
    "boxes = target['boxes']\n",
    "labels = target['labels']\n",
    "for box in boxes:\n",
    "    cv2.rectangle(image, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "plt.imshow(image)\n",
    "idx2classes = {idx: cls for cls, idx in classes.items()}\n",
    "print([idx2classes[label] for label in aug_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(xml_paths)\n",
    "# for xml_path in xml_paths:\n",
    "#     image_info, label_info = get_info(xml_path)\n",
    "#     image = cv2.imread(str(image_dir.joinpath(image_info['image_name'])))\n",
    "#     for info in label_info:\n",
    "#         b = np.random.randint(0, 255)\n",
    "#         g = np.random.randint(100, 255)\n",
    "#         r = np.random.randint(0, 150)\n",
    "#         cv2.rectangle(image, tuple(info['bbox'][:2]), tuple(info['bbox'][2:]), color=(b, g, r), thickness=3)\n",
    "#         cv2.putText(image, info['label'], org=tuple(info['bbox'][:2]),\n",
    "#                     fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n",
    "#                     color=(b, g, r), thickness=2, lineType=cv2.LINE_AA)\n",
    "#     cv2.imshow('annotation', image)\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "classes = []\n",
    "for xml_path in xml_paths:\n",
    "    tree = ET.parse(str(xml_path))\n",
    "    objects = tree.findall('object')\n",
    "    for obj in objects:\n",
    "        classes.append(obj.find('name').text)\n",
    "\n",
    "classes = dict(Counter(classes))\n",
    "print(classes)\n",
    "print('\\nnum_classes: {}'.format(len(list(classes.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ET.parse(str(xml_paths[0]))\n",
    "image = cv2.imread(str(image_dir.joinpath(etree.find('filename').text)))\n",
    "boxes = np.int32([[obj.find('bndbox').find('xmin').text,\n",
    "                   obj.find('bndbox').find('ymin').text,\n",
    "                   obj.find('bndbox').find('xmax').text,\n",
    "                   obj.find('bndbox').find('ymax').text] for obj in etree.findall('object')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in boxes:\n",
    "    cv2.rectangle(image, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize():\n",
    "    def __init__(self, height=None, width=None):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "    \n",
    "    def __call__(self, image, boxes):\n",
    "        h, w = image.shape[:2]\n",
    "        boxes = np.int32(boxes)\n",
    "        if self.height and self.width is None:\n",
    "            h_, w_ = self.height, int(w * self.height / h)\n",
    "            image = cv2.resize(image, dsize=(w_, h_), interpolation=cv2.INTER_LINEAR)\n",
    "        elif self.width and self.height is None:\n",
    "            h_, w_ = int(h * width / w), w\n",
    "            image = cv2.resize(image, dsize=(w_, h_), interpolation=cv2.INTER_LINEAR)\n",
    "        elif self.width and self.height:\n",
    "            h_, w_ = self.height, self.width\n",
    "            image = cv2.resize(image, dsize=(w_, h_), interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            h_, w_ = h, w\n",
    "        rh, rw = h_ / h, w_ / w\n",
    "        boxes[:, [0, 2]] = boxes[:, [0, 2]] * rw\n",
    "        boxes[:, [1, 3]] = boxes[:, [1, 3]] * rh\n",
    "        return image, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_, boxes_ = Resize(height=1000, width=1000)(image, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in boxes_:\n",
    "    cv2.rectangle(image_, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "plt.imshow(image_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip():\n",
    "    def __init__(self, mode=0):\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, image, boxes):\n",
    "        boxes = np.int32(boxes)\n",
    "        bbs, img = boxes.copy(), image.copy()\n",
    "        cx, cy = img.shape[1] // 2, img.shape[0] // 2\n",
    "        if self.mode == 0:\n",
    "            img = img[:, ::-1, :]\n",
    "            bbs[:, [0, 2]] = 2 * cx - boxes[:, [0, 2]]\n",
    "        elif self.mode == 1:\n",
    "            img = img[::-1, :, :]\n",
    "            bbs[:, [1, 3]] = 2 * cy - boxes[:, [1, 3]]\n",
    "        elif self.mode == -1:\n",
    "            img = img[::-1, ::-1, :]\n",
    "            bbs[:, [0, 2]] = 2 * cx - boxes[:, [0, 2]]\n",
    "            bbs[:, [1, 3]] = 2 * cy - boxes[:, [1, 3]]\n",
    "            bbs[:, [0, 1, 2, 3]] = bbs[:, [2, 3, 0, 1]]\n",
    "\n",
    "        return img.astype(np.uint8), bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ET.parse(str(xml_paths[0]))\n",
    "img_ = cv2.imread(str(image_dir.joinpath(etree.find('filename').text)))\n",
    "bbs_ = np.int32([[obj.find('bndbox').find('xmin').text,\n",
    "                   obj.find('bndbox').find('ymin').text,\n",
    "                   obj.find('bndbox').find('xmax').text,\n",
    "                   obj.find('bndbox').find('ymax').text] for obj in etree.findall('object')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_, boxes_ = Flip(mode=1)(img_, bbs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in boxes_:\n",
    "    image_ = cv2.rectangle(image_, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "\n",
    "plt.imshow(image_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rotation():\n",
    "    def __init__(self, angle, scale):\n",
    "        self.angle = angle\n",
    "        self.scale = scale\n",
    "\n",
    "    def _get_box_corners(self, boxes):\n",
    "        ws = (boxes[:, 2] - boxes[:, 0]).reshape(-1, 1)\n",
    "        hs = (boxes[:, 3] - boxes[:, 1]).reshape(-1, 1)\n",
    "        x1, y1 = boxes[:, 0].reshape(-1, 1), boxes[:, 1].reshape(-1, 1)\n",
    "        x2, y2 = x1 + ws, y1\n",
    "        x3, y3 = boxes[:, 2].reshape(-1, 1), boxes[:, 3].reshape(-1, 1)\n",
    "        x4, y4 = x1, y1 + hs\n",
    "        corners = np.concatenate((x1, y1, x2, y2, x3, y3, x4, y4), axis=1)\n",
    "\n",
    "        return corners\n",
    "    \n",
    "    def _get_rotation_matrix2D(self, pts, angle, scale):\n",
    "        cx, cy = pts\n",
    "        angle = angle * np.pi / 180.\n",
    "        # translate center of image to origin\n",
    "        MT1 = np.float32([[1, 0, -cx],\n",
    "                          [0, 1, -cy],\n",
    "                          [0, 0, 1]])\n",
    "        # rotate image\n",
    "        MR = np.float32([[np.cos(angle), -np.sin(angle), 0],\n",
    "                         [np.sin(angle), np.cos(angle), 0],\n",
    "                         [0, 0, 1]])\n",
    "        # translate center of image to original position\n",
    "        MT2 = np.float32([[1, 0, cx],\n",
    "                          [0, 1, cy],\n",
    "                          [0, 0, 1]])\n",
    "        # scale image\n",
    "        MS = np.float32([[scale, 0, 0],\n",
    "                         [0, scale, 0],\n",
    "                         [0, 0, 1]])\n",
    "        # get matrix transformation\n",
    "        M = MT2 @ (MS @ (MR @ MT1))  # 3x3\n",
    "\n",
    "        return M[:2, :]  # 2x3\n",
    "\n",
    "    def __call__(self, image, boxes):\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        M = self._get_rotation_matrix2D(pts=(w // 2, h // 2), angle=self.angle, scale=self.scale)\n",
    "\n",
    "        # expand image\n",
    "        cos, sin = np.abs(M[0, 0]), np.abs(M[1, 0]) # note!!! using abs why???\n",
    "        nw = int((h * sin) + (w * cos))\n",
    "        nh = int((h * cos) + (w * sin))\n",
    "        M[0, 2] += (nw / 2) - w // 2\n",
    "        M[1, 2] += (nh / 2) - h // 2\n",
    "\n",
    "        image = cv2.warpAffine(image.copy(), M, (nw, nh))\n",
    "\n",
    "        corners = self._get_box_corners(boxes).reshape(-1, 2)\n",
    "        corners = np.concatenate((corners, np.ones(shape=(corners.shape[0], 1), dtype=type(corners))), axis=1)\n",
    "        corners = (np.dot(M, corners.T).T).reshape(-1, 8)\n",
    "\n",
    "        boxes = np.zeros(shape=(corners.shape[0], 4))\n",
    "        boxes[:, 0] = np.min(corners[:, [0, 2, 4, 6]], axis=1)\n",
    "        boxes[:, 1] = np.min(corners[:, [1, 3, 5, 7]], axis=1)\n",
    "        boxes[:, 2] = np.max(corners[:, [0, 2, 4, 6]], axis=1)\n",
    "        boxes[:, 3] = np.max(corners[:, [1, 3, 5, 7]], axis=1)\n",
    "\n",
    "        return image, np.int32(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ET.parse(str(xml_paths[0]))\n",
    "img = cv2.imread(str(image_dir.joinpath(etree.find('filename').text)))\n",
    "bbs = np.int32([[obj.find('bndbox').find('xmin').text,\n",
    "               obj.find('bndbox').find('ymin').text,\n",
    "               obj.find('bndbox').find('xmax').text,\n",
    "               obj.find('bndbox').find('ymax').text] for obj in etree.findall('object')])\n",
    "\n",
    "for box in bbs:\n",
    "    cv2.rectangle(img, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, boxes = Rotation(angle=-45, scale=2)(img, bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for box in boxes:\n",
    "    cv2.rectangle(image, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "    cv2.circle(image, tuple(box[:2]), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "    cv2.circle(image, tuple(box[2:]), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shear():\n",
    "    def __init__(self, angle_x=None, angle_y=None):\n",
    "        self.angle_x = angle_x\n",
    "        self.angle_y = angle_y\n",
    "\n",
    "    def _get_box_corners(self, boxes):\n",
    "        ws = (boxes[:, 2] - boxes[:, 0]).reshape(-1, 1)\n",
    "        hs = (boxes[:, 3] - boxes[:, 1]).reshape(-1, 1)\n",
    "        x1, y1 = boxes[:, 0].reshape(-1, 1), boxes[:, 1].reshape(-1, 1)\n",
    "        x2, y2 = x1 + ws, y1\n",
    "        x3, y3 = boxes[:, 2].reshape(-1, 1), boxes[:, 3].reshape(-1, 1)\n",
    "        x4, y4 = x1, y1 + hs\n",
    "        corners = np.concatenate((x1, y1, x2, y2, x3, y3, x4, y4), axis=1)\n",
    "\n",
    "        return corners\n",
    "    \n",
    "    def _get_shear_matrix2D(self, pts, angle_x, angle_y):\n",
    "        cx, cy = pts\n",
    "        MT1 = np.float32([[1, 0, -cx],\n",
    "                          [0, 1, -cy],\n",
    "                          [0, 0, 1]])\n",
    "        MT2 = np.float32([[1, 0, cx],\n",
    "                          [0, 1, cy],\n",
    "                          [0, 0, 1]])\n",
    "        if angle_x is not None and angle_x != 0:\n",
    "            angle_x = angle_x * np.pi / 180.\n",
    "            MSx = np.float32([[1, np.cos(angle_x) / np.sin(angle_x), 0],\n",
    "                              [0, 1, 0],\n",
    "                              [0, 0, 1]])\n",
    "        if angle_y is not None and angle_y != 0:\n",
    "            angle_y = angle_y * np.pi / 180.\n",
    "            MSy = np.float32([[1, 0, 0],\n",
    "                              [np.cos(angle_y) / np.sin(angle_y), 1, 0],\n",
    "                              [0, 0, 1]])\n",
    "\n",
    "        if angle_x and angle_y is None:\n",
    "            M = (MT2 @ (MSx @ MT1))[:2, :]\n",
    "        elif angle_y and angle_x is None:\n",
    "            M = (MT2 @ (MSy @ MT1))[:2, :] \n",
    "        elif angle_x and angle_y:\n",
    "            M = (MT2 @ (MSy @ (MSx @ MT1)))[:2, :]\n",
    "        else:\n",
    "            M = None\n",
    "\n",
    "        return M\n",
    "\n",
    "    def __call__(self, image, boxes):\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        M = self._get_shear_matrix2D(pts=(w // 2, h // 2), angle_x=self.angle_x, angle_y=self.angle_y)\n",
    "        \n",
    "        if M is not None:\n",
    "            cos, sin = np.abs(M[0, 0]), np.abs(M[1, 0]) # note!!! using abs why???\n",
    "            nw = int((h * sin) + (w * cos))\n",
    "            nh = int((h * cos) + (w * sin))\n",
    "            M[0, 2] += (nw / 2) - w // 2\n",
    "            M[1, 2] += (nh / 2) - h // 2\n",
    "\n",
    "            image = cv2.warpAffine(image.copy(), M, (nw, nh))\n",
    "\n",
    "            corners = self._get_box_corners(boxes).reshape(-1, 2)\n",
    "            corners = np.concatenate((corners, np.ones(shape=(corners.shape[0], 1), dtype=type(corners))), axis=1)\n",
    "            corners = (np.dot(M, corners.T).T).reshape(-1, 8)\n",
    "\n",
    "            boxes = np.zeros(shape=(corners.shape[0], 4))\n",
    "            boxes[:, 0] = np.min(corners[:, [0, 2, 4, 6]], axis=1)\n",
    "            boxes[:, 1] = np.min(corners[:, [1, 3, 5, 7]], axis=1)\n",
    "            boxes[:, 2] = np.max(corners[:, [0, 2, 4, 6]], axis=1)\n",
    "            boxes[:, 3] = np.max(corners[:, [1, 3, 5, 7]], axis=1)\n",
    "\n",
    "        return image, np.int32(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ET.parse(str(xml_paths[0]))\n",
    "img = cv2.imread(str(image_dir.joinpath(etree.find('filename').text)))\n",
    "bbs = np.int32([[obj.find('bndbox').find('xmin').text,\n",
    "               obj.find('bndbox').find('ymin').text,\n",
    "               obj.find('bndbox').find('xmax').text,\n",
    "               obj.find('bndbox').find('ymax').text] for obj in etree.findall('object')])\n",
    "\n",
    "for box in bbs:\n",
    "    cv2.rectangle(img, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, boxes = Shear(angle_x=-80, angle_y=-80)(img, bbs)\n",
    "for box in boxes:\n",
    "    cv2.rectangle(image, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)\n",
    "    cv2.circle(image, tuple(box[:2]), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "    cv2.circle(image, tuple(box[2:]), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMGAUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ET.parse(str(xml_paths[0]))\n",
    "img = cv2.imread(str(image_dir.joinpath(etree.find('filename').text)))\n",
    "bbs = np.int32([[obj.find('bndbox').find('xmin').text,\n",
    "               obj.find('bndbox').find('ymin').text,\n",
    "               obj.find('bndbox').find('xmax').text,\n",
    "               obj.find('bndbox').find('ymax').text] for obj in etree.findall('object')])\n",
    "image = img\n",
    "bbs = BoundingBoxesOnImage([\n",
    "    BoundingBox(x1=bb[0], y1=bb[1], x2=bb[2], y2=bb[3]) for bb in bbs], shape=image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "#     iaa.Multiply((1.2, 1.5)), # change brightness, doesn't affect BBs\n",
    "    iaa.Affine(rotate=(45),fit_output=True),\n",
    "    iaa.Fliplr(p=1),\n",
    "#     iaa.Resize(size=1000),\n",
    "#     iaa.Affine(shear=(30))\n",
    "])\n",
    "\n",
    "image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bb in bbs_aug:\n",
    "    box = np.int32([bb.x1, bb.y1, bb.x2, bb.y2])\n",
    "    cv2.rectangle(image_aug, tuple(box[:2]), tuple(box[2:]), color=(0, 255, 0), thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree = ET.parse(str(xml_paths[0]))\n",
    "img = cv2.imread(str(image_dir.joinpath(etree.find('filename').text)))\n",
    "bbs = np.int32([[obj.find('bndbox').find('xmin').text,\n",
    "               obj.find('bndbox').find('ymin').text,\n",
    "               obj.find('bndbox').find('xmax').text,\n",
    "               obj.find('bndbox').find('ymax').text] for obj in etree.findall('object')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.rot90(img, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getRotationMatrix2D(())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
