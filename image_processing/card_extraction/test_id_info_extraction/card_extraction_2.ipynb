{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maskrcnn import MaskrcnnResnet50FPN\n",
    "\n",
    "num_classes = 3\n",
    "weight_path = './weight/2011110823/best_model_31_dice_mAP=0.9705.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskrcnnResnet50FPN(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(weight_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_size = (768, 768)\n",
    "\n",
    "def preprocess(image):\n",
    "    sample = cv2.resize(image, dsize=image_size)\n",
    "    sample = torch.from_numpy(sample).to(torch.float).to(device)\n",
    "    samples = sample.unsqueeze(dim=0).permute(0, 3, 1, 2)\n",
    "    samples = (samples - samples.mean()) / samples.std() #Tùy thuộc vào lúc train norm cách nào\n",
    "    return image, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image, samples):\n",
    "    with torch.no_grad():\n",
    "        preds = model(samples)\n",
    "    return image, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "from shapely.geometry import box, Point, Polygon\n",
    "\n",
    "\n",
    "class EnclosingQuadrilateral:\n",
    "    def __init__(self):\n",
    "        self.binary_threshold = 0.6\n",
    "        self.area_threshold = 0.0\n",
    "        self.vertical_threshold = 20\n",
    "        self.iou_threshold = 0.8\n",
    "\n",
    "    def _order_points(self, points):\n",
    "        assert len(points) == 4, 'Length of points must be 4'\n",
    "        left = sorted(points, key=lambda p: p[0])[:2]\n",
    "        right = sorted(points, key=lambda p: p[0])[2:]\n",
    "        tl, bl = sorted(left, key=lambda p: p[1])\n",
    "        tr, br = sorted(right, key=lambda p: p[1])\n",
    "        return [tl, tr, br, bl]\n",
    "\n",
    "    def _compute_iou(self, polyA, polyB):\n",
    "        iou = 0.\n",
    "        polyA = Polygon(polyA)\n",
    "        polyB = Polygon(polyB)\n",
    "        if polyA.intersects(polyB):\n",
    "            iou = polyA.intersection(polyB).area / polyA.union(polyB).area\n",
    "        return iou\n",
    "\n",
    "    def _intersection_point(self, line1, line2):\n",
    "        a1 = line1[1][1] - line1[0][1]\n",
    "        b1 = line1[0][0] - line1[1][0]\n",
    "        a2 = line2[1][1] - line2[0][1]\n",
    "        b2 = line2[0][0] - line2[1][0]\n",
    "        determinant = a1 * b2 - a2 * b1\n",
    "        if determinant == 0:\n",
    "            return None\n",
    "        c1 = (a1 / determinant) * line1[0][0] + (b1 / determinant) * line1[0][1]\n",
    "        c2 = (a2 / determinant) * line2[0][0] + (b2 / determinant) * line2[0][1]\n",
    "        x = b2 * c1 - b1 * c2\n",
    "        y = a1 * c2 - a2 * c1\n",
    "        return [int(x), int(y)]\n",
    "\n",
    "    def _convex_hulls(self, pred, binary_threshold=0.6, area_threshold=0.0, vertical_threshold=20):\n",
    "        convex_hulls = []\n",
    "        binary_image = (pred > binary_threshold).astype(np.uint8)\n",
    "        binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, np.ones(shape=(5, 5), dtype=np.uint8))\n",
    "        num_label, label = cv2.connectedComponents(binary_image)\n",
    "        for i in range(1, num_label):\n",
    "            contours, _ = cv2.findContours((label == i).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contour = contours[0]\n",
    "            if cv2.contourArea(contour) > area_threshold * pred.size:\n",
    "                epsilon = 0.009 * cv2.arcLength(contour, closed=True)\n",
    "                approx_contour = cv2.approxPolyDP(contour, epsilon, closed=True)\n",
    "                convex_hull = cv2.convexHull(approx_contour)  # approximate contour to reduce num of points\n",
    "                for inc in range(5):\n",
    "                    if convex_hull.shape[0] <= vertical_threshold:\n",
    "                        break\n",
    "                    epsilon = 0.002 * (1 + inc) * cv2.arcLength(contour, closed=True)\n",
    "                    convex_hull = cv2.approxPolyDP(convex_hull, epsilon, closed=True)\n",
    "\n",
    "                if 4 <= convex_hull.shape[0] <= vertical_threshold:\n",
    "                    convex_hulls.append(np.squeeze(np.array(convex_hull), axis=1))\n",
    "\n",
    "        return convex_hulls\n",
    "\n",
    "    def _enclosing_quadrilateral(self, pred, convex_hulls, iou_threshold):\n",
    "        enclosing_quads = []\n",
    "        x1, x2 = [-pred.shape[0], 2 * pred.shape[0]]\n",
    "        y1, y2 = [-pred.shape[1], 2 * pred.shape[1]]\n",
    "        boundary = box(x1, y1, x2, y2)\n",
    "        for polygon in convex_hulls:\n",
    "            num_verticals = len(polygon)\n",
    "            max_iou = 0.\n",
    "            enclosing_quad = None\n",
    "            for (x, y, z, t) in itertools.combinations(range(num_verticals), 4):\n",
    "                lines = [\n",
    "                    [polygon[x], polygon[(x + 1) % num_verticals]],\n",
    "                    [polygon[y], polygon[(y + 1) % num_verticals]],\n",
    "                    [polygon[z], polygon[(z + 1) % num_verticals]],\n",
    "                    [polygon[t], polygon[(t + 1) % num_verticals]]\n",
    "                ]\n",
    "                points = []\n",
    "                for i in range(4):\n",
    "                    point = self._intersection_point(lines[i], lines[(i + 1) % 4])\n",
    "                    if (not point) or (point in points) or (not boundary.contains(Point(point))):\n",
    "                        break\n",
    "                    points.append(point)\n",
    "\n",
    "                if len(points) == 4 and Polygon(self._order_points(points)).is_valid:\n",
    "                    candidate_quad = self._order_points(points)\n",
    "                    iou = self._compute_iou(candidate_quad, polygon)\n",
    "                    if iou > max_iou and iou > iou_threshold:\n",
    "                        enclosing_quad = candidate_quad\n",
    "                        max_iou = iou\n",
    "\n",
    "            if enclosing_quad:\n",
    "                enclosing_quads.append(enclosing_quad)\n",
    "\n",
    "        return enclosing_quads\n",
    "    \n",
    "    def perspective_transform(self, original_image, pred_mask, quad):\n",
    "        width_ratio = original_image.shape[1] / pred_mask.shape[1]\n",
    "        height_ratio = original_image.shape[0] / pred_mask.shape[0] \n",
    "        quad = np.array(quad, dtype=np.float32)\n",
    "        quad[:, 0] = quad[:, 0] * width_ratio\n",
    "        quad[:, 1] = quad[:, 1] * height_ratio\n",
    "        tl, tr, br, bl = quad\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [maxWidth - 1, 0],\n",
    "            [maxWidth - 1, maxHeight - 1],\n",
    "            [0, maxHeight - 1]], dtype = \"float32\")\n",
    "        M = cv2.getPerspectiveTransform(quad, dst)\n",
    "        warped_image = cv2.warpPerspective(original_image, M, (maxWidth, maxHeight))\n",
    "        return warped_image, [tl, tr, br, bl]\n",
    "\n",
    "    def __call__(self, original_image, pred_mask):\n",
    "        warped_images = []\n",
    "        convex_hulls = self._convex_hulls(pred_mask,\n",
    "                                          self.binary_threshold,\n",
    "                                          self.area_threshold,\n",
    "                                          self.vertical_threshold)\n",
    "        enclosing_quads = self._enclosing_quadrilateral(pred_mask,\n",
    "                                                        convex_hulls,\n",
    "                                                        self.iou_threshold)\n",
    "        for quad in enclosing_quads:\n",
    "            warped_images.append(self.perspective_transform(original_image, pred_mask, quad))\n",
    "\n",
    "        return warped_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(image, preds):\n",
    "    pred = preds[0]\n",
    "    boxes = pred['boxes']\n",
    "    masks = pred['masks']\n",
    "    scores = pred['scores']\n",
    "    labels = pred['labels']\n",
    "    \n",
    "    indices = scores > 0.5\n",
    "    masks = masks[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    indices = torchvision.ops.nms(boxes, scores, 0.5)\n",
    "    masks = masks[indices]\n",
    "    scores = scores[indices]\n",
    "    labels = labels[indices]  \n",
    "    \n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    masks = masks.squeeze(1).detach().cpu().numpy()\n",
    "    \n",
    "    warped_images = []\n",
    "    min_enclosing_quad = EnclosingQuadrilateral()\n",
    "    for mask in masks:\n",
    "        warped_image = min_enclosing_quad(image, mask)\n",
    "        warped_images += warped_image\n",
    "    \n",
    "    return warped_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Closing Quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = cv2.imread('./test/mask.jpg', cv2.IMREAD_GRAYSCALE) / 255.\n",
    "\n",
    "enclosing_quad = EnclosingQuadrilateral()\n",
    "convex_hulls = enclosing_quad._convex_hulls(pred_mask, 0.6, 0, 20)\n",
    "enclosing_quads = enclosing_quad._enclosing_quadrilateral(pred_mask,\n",
    "                                                convex_hulls,\n",
    "                                                0.8)\n",
    "\n",
    "for quad in enclosing_quads:\n",
    "    quad = np.int32(quad)\n",
    "    test_quad = np.stack([pred_mask] * 3, axis=2)\n",
    "    cv2.polylines(test_quad, [quad], True, (255, 0, 0), 3)\n",
    "    cv2.imshow('find quad', test_quad)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "test_image = cv2.imread('test/GiayCMND.png')\n",
    "image, samples = preprocess(test_image)\n",
    "image, preds = process(image, samples)\n",
    "warped_images = postprocess(image, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for warped_image in warped_images:\n",
    "    cv2.imshow('result', warped_image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maskrcnn import MaskrcnnResnet50FPN\n",
    "\n",
    "\n",
    "class CardExtraction:\n",
    "    def __init__(self, num_classes, weight_path, image_size):\n",
    "        self.image_size = image_size\n",
    "        self.model = MaskrcnnResnet50FPN(num_classes=num_classes)\n",
    "        self.model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        sample = cv2.resize(image, dsize=self.image_size)\n",
    "        sample = torch.from_numpy(sample).to(torch.float).to(self.device)\n",
    "        samples = sample.unsqueeze(dim=0).permute(0, 3, 1, 2)\n",
    "        samples = (samples - samples.mean()) / samples.std() \n",
    "        return image, samples\n",
    "    \n",
    "    def process(self, image, samples):\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(samples)\n",
    "        return image, preds\n",
    "            \n",
    "    def postprocess(self, image, preds):\n",
    "        pred = preds[0]\n",
    "        boxes = pred['boxes']\n",
    "        masks = pred['masks']\n",
    "        scores = pred['scores']\n",
    "        labels = pred['labels']\n",
    "\n",
    "        indices = torchvision.ops.nms(boxes, scores, 0.5)\n",
    "        masks = masks[indices]\n",
    "        scores = scores[indices]\n",
    "        labels = labels[indices]  \n",
    "        \n",
    "        indices = scores > 0.5\n",
    "        masks = masks[indices]\n",
    "        labels = labels[indices]\n",
    "\n",
    "\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        masks = masks.squeeze(1).detach().cpu().numpy()\n",
    "\n",
    "        warped_images = []\n",
    "        min_enclosing_quad = EnclosingQuadrilateral()\n",
    "        for mask in masks:\n",
    "            warped_image = min_enclosing_quad(image, mask)\n",
    "            warped_images += warped_image\n",
    "\n",
    "        return warped_images\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        output = self.preprocess(*args)\n",
    "        output = self.process(*output)\n",
    "        output = self.postprocess(*output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('test/GiayCMND.png')\n",
    "card_extractor = CardExtraction(3, \n",
    "                                './weight/2011110823/best_model_31_dice_mAP=0.9705.pt', \n",
    "                                image_size=(768, 768))\n",
    "warped_images = card_extractor(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for warped_image in warped_images:\n",
    "    cv2.imshow('result', warped_image[0])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    image_patterns = ['*.jpg', '*.png', '*.jpeg', '*.JPG', '*.PNG', '*.JPEG']\n",
    "    input_dir = Path('./test/test/')\n",
    "    image_paths = []\n",
    "    for image_pattern in image_patterns:\n",
    "        image_paths += list(input_dir.glob(f'**/{image_pattern}'))\n",
    "        \n",
    "    card_extractor = CardExtraction(3, \n",
    "                                './weight/2011110823/best_model_31_dice_mAP=0.9705.pt', \n",
    "                                image_size=(768, 768))\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(str(image_path))\n",
    "        warped_images = card_extractor(image)\n",
    "        for i in range(len(warped_images)):\n",
    "            cv2.imwrite(f'./test/test/output/{image_path.stem}_{i}.jpg', warped_images[i][0])\n",
    "            pts = np.int32(warped_images[i][1])\n",
    "            cv2.polylines(image, [pts], True, (0, 255, 0), 2) \n",
    "            cv2.imwrite(f'./test/test/output/{image_path.stem}_box_{i}.jpg', image)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
